#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste Completo do Sistema Otimizado - Lotof√°cil
Valida√ß√£o das otimiza√ß√µes implementadas
"""

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class TesteSistemaOtimizado:
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.modelo_dir = os.path.join(self.base_dir, 'modelo')
        self.dados_dir = os.path.join(self.base_dir, 'dados')
        self.resultados_dir = os.path.join(self.base_dir, 'experimentos', 'resultados')
        
        # Criar diret√≥rios se n√£o existirem
        os.makedirs(self.resultados_dir, exist_ok=True)
        
        self.resultados = {
            'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'testes_realizados': [],
            'modelos_testados': {},
            'performance_geral': {},
            'validacoes': {},
            'recomendacoes': []
        }
    
    def carregar_dados_teste(self):
        """Carrega dados para teste"""
        print("üìä Carregando dados de teste...")
        
        try:
            # Tentar carregar dados processados
            dados_path = os.path.join(self.dados_dir, 'dados_processados.csv')
            if os.path.exists(dados_path):
                df = pd.read_csv(dados_path)
                print(f"   ‚úÖ Dados carregados: {df.shape}")
                return df
            
            # Se n√£o existir, criar dados de exemplo
            print("   ‚ö†Ô∏è  Criando dados de exemplo para teste...")
            np.random.seed(42)
            n_samples = 1000
            
            # Simular dados de jogos da Lotof√°cil
            dados = []
            for i in range(n_samples):
                jogo = sorted(np.random.choice(range(1, 26), 15, replace=False))
                dados.append(jogo)
            
            df = pd.DataFrame(dados, columns=[f'num_{i+1}' for i in range(15)])
            
            # Salvar dados de exemplo
            df.to_csv(dados_path, index=False)
            print(f"   ‚úÖ Dados de exemplo criados: {df.shape}")
            return df
            
        except Exception as e:
            print(f"   ‚ùå Erro ao carregar dados: {e}")
            return None
    
    def testar_modelos_otimizados(self):
        """Testa os modelos otimizados"""
        print("\nü§ñ Testando modelos otimizados...")
        
        modelos_dir = os.path.join(self.modelo_dir, 'optimized_models')
        if not os.path.exists(modelos_dir):
            print("   ‚ùå Diret√≥rio de modelos otimizados n√£o encontrado")
            return
        
        modelos_testados = {}
        
        # Listar modelos dispon√≠veis
        for arquivo in os.listdir(modelos_dir):
            if arquivo.endswith('.pkl'):
                modelo_path = os.path.join(modelos_dir, arquivo)
                nome_modelo = arquivo.replace('.pkl', '')
                
                try:
                    print(f"   üîç Testando {nome_modelo}...")
                    
                    # Carregar modelo
                    with open(modelo_path, 'rb') as f:
                        modelo = pickle.load(f)
                    
                    # Informa√ß√µes do modelo
                    info_modelo = {
                        'arquivo': arquivo,
                        'tamanho_arquivo': os.path.getsize(modelo_path),
                        'tipo': str(type(modelo)),
                        'status': 'carregado_com_sucesso'
                    }
                    
                    # Tentar fazer predi√ß√£o de teste
                    if hasattr(modelo, 'predict'):
                        # Criar dados de teste simples
                        X_teste = np.random.rand(10, 15)
                        try:
                            predicoes = modelo.predict(X_teste)
                            info_modelo['predicao_teste'] = 'sucesso'
                            info_modelo['formato_saida'] = str(type(predicoes[0]))
                        except Exception as e:
                            info_modelo['predicao_teste'] = f'erro: {str(e)}'
                    
                    modelos_testados[nome_modelo] = info_modelo
                    print(f"   ‚úÖ {nome_modelo}: OK")
                    
                except Exception as e:
                    modelos_testados[nome_modelo] = {
                        'arquivo': arquivo,
                        'status': 'erro',
                        'erro': str(e)
                    }
                    print(f"   ‚ùå {nome_modelo}: {e}")
        
        self.resultados['modelos_testados'] = modelos_testados
        return modelos_testados
    
    def validar_arquivos_resultados(self):
        """Valida arquivos de resultados gerados"""
        print("\nüìÅ Validando arquivos de resultados...")
        
        arquivos_validados = {}
        
        # Verificar arquivos de otimiza√ß√µes
        for arquivo in os.listdir(self.resultados_dir):
            if 'otimizacoes' in arquivo and arquivo.endswith('.json'):
                arquivo_path = os.path.join(self.resultados_dir, arquivo)
                
                try:
                    with open(arquivo_path, 'r', encoding='utf-8') as f:
                        dados = json.load(f)
                    
                    info_arquivo = {
                        'tamanho': os.path.getsize(arquivo_path),
                        'chaves_principais': list(dados.keys()) if isinstance(dados, dict) else 'n√£o_dict',
                        'status': 'v√°lido'
                    }
                    
                    # Verificar m√©tricas espec√≠ficas
                    if isinstance(dados, dict):
                        if 'metricas' in dados:
                            metricas = dados['metricas']
                            info_arquivo['accuracy'] = metricas.get('accuracy', 'n√£o_encontrado')
                            info_arquivo['precision'] = metricas.get('precision', 'n√£o_encontrado')
                        
                        if 'ensemble_performance' in dados:
                            info_arquivo['ensemble_accuracy'] = dados['ensemble_performance'].get('accuracy', 'n√£o_encontrado')
                    
                    arquivos_validados[arquivo] = info_arquivo
                    print(f"   ‚úÖ {arquivo}: V√°lido")
                    
                except Exception as e:
                    arquivos_validados[arquivo] = {
                        'status': 'erro',
                        'erro': str(e)
                    }
                    print(f"   ‚ùå {arquivo}: {e}")
        
        self.resultados['validacoes']['arquivos_resultados'] = arquivos_validados
        return arquivos_validados
    
    def testar_performance_sistema(self):
        """Testa performance geral do sistema"""
        print("\n‚ö° Testando performance do sistema...")
        
        performance = {
            'tempo_carregamento_modelos': 0,
            'tempo_predicao': 0,
            'uso_memoria': 0,
            'status_geral': 'ok'
        }
        
        try:
            import time
            import psutil
            
            # Medir uso de mem√≥ria inicial
            memoria_inicial = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            # Testar carregamento de modelos
            inicio = time.time()
            modelos = self.testar_modelos_otimizados()
            fim = time.time()
            performance['tempo_carregamento_modelos'] = fim - inicio
            
            # Medir uso de mem√≥ria final
            memoria_final = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            performance['uso_memoria'] = memoria_final - memoria_inicial
            
            print(f"   ‚è±Ô∏è  Tempo carregamento: {performance['tempo_carregamento_modelos']:.2f}s")
            print(f"   üíæ Uso de mem√≥ria: {performance['uso_memoria']:.2f}MB")
            
        except Exception as e:
            performance['status_geral'] = f'erro: {str(e)}'
            print(f"   ‚ùå Erro no teste de performance: {e}")
        
        self.resultados['performance_geral'] = performance
        return performance
    
    def gerar_recomendacoes(self):
        """Gera recomenda√ß√µes baseadas nos testes"""
        print("\nüí° Gerando recomenda√ß√µes...")
        
        recomendacoes = []
        
        # Analisar modelos testados
        modelos_ok = sum(1 for m in self.resultados['modelos_testados'].values() 
                        if m.get('status') == 'carregado_com_sucesso')
        total_modelos = len(self.resultados['modelos_testados'])
        
        if modelos_ok == total_modelos and total_modelos > 0:
            recomendacoes.append("‚úÖ Todos os modelos foram carregados com sucesso")
        elif modelos_ok > 0:
            recomendacoes.append(f"‚ö†Ô∏è  {modelos_ok}/{total_modelos} modelos funcionando corretamente")
        else:
            recomendacoes.append("‚ùå Nenhum modelo funcionando - revisar implementa√ß√£o")
        
        # Analisar performance
        if 'performance_geral' in self.resultados:
            perf = self.resultados['performance_geral']
            if perf.get('tempo_carregamento_modelos', 0) > 10:
                recomendacoes.append("‚ö†Ô∏è  Tempo de carregamento alto - considerar otimiza√ß√£o")
            if perf.get('uso_memoria', 0) > 500:
                recomendacoes.append("‚ö†Ô∏è  Alto uso de mem√≥ria - considerar otimiza√ß√£o")
        
        # Recomenda√ß√µes gerais
        recomendacoes.extend([
            "üîÑ Implementar monitoramento cont√≠nuo de performance",
            "üìä Configurar logging detalhado para produ√ß√£o",
            "üéØ Testar com dados reais de produ√ß√£o",
            "üîí Implementar valida√ß√£o de entrada robusta",
            "‚ö° Considerar cache para predi√ß√µes frequentes"
        ])
        
        self.resultados['recomendacoes'] = recomendacoes
        
        for rec in recomendacoes:
            print(f"   {rec}")
        
        return recomendacoes
    
    def executar_teste_completo(self):
        """Executa todos os testes do sistema"""
        print("üöÄ INICIANDO TESTE COMPLETO DO SISTEMA OTIMIZADO")
        print("=" * 60)
        
        # Registrar in√≠cio do teste
        self.resultados['testes_realizados'].append('inicio_teste_completo')
        
        # 1. Carregar dados
        dados = self.carregar_dados_teste()
        if dados is not None:
            self.resultados['testes_realizados'].append('carregamento_dados')
        
        # 2. Testar modelos
        modelos = self.testar_modelos_otimizados()
        if modelos:
            self.resultados['testes_realizados'].append('teste_modelos')
        
        # 3. Validar arquivos
        arquivos = self.validar_arquivos_resultados()
        if arquivos:
            self.resultados['testes_realizados'].append('validacao_arquivos')
        
        # 4. Testar performance
        performance = self.testar_performance_sistema()
        if performance:
            self.resultados['testes_realizados'].append('teste_performance')
        
        # 5. Gerar recomenda√ß√µes
        recomendacoes = self.gerar_recomendacoes()
        if recomendacoes:
            self.resultados['testes_realizados'].append('geracao_recomendacoes')
        
        # Salvar resultados
        self.salvar_resultados()
        
        # Exibir resumo
        self.exibir_resumo()
    
    def salvar_resultados(self):
        """Salva os resultados dos testes"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        arquivo_resultado = os.path.join(self.resultados_dir, f'teste_sistema_completo_{timestamp}.json')
        
        try:
            with open(arquivo_resultado, 'w', encoding='utf-8') as f:
                json.dump(self.resultados, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nüíæ Resultados salvos em: {arquivo_resultado}")
            
        except Exception as e:
            print(f"\n‚ùå Erro ao salvar resultados: {e}")
    
    def exibir_resumo(self):
        """Exibe resumo dos testes"""
        print("\n" + "=" * 60)
        print("üìã RESUMO DO TESTE COMPLETO")
        print("=" * 60)
        
        # Status dos testes
        print(f"üîç Testes realizados: {len(self.resultados['testes_realizados'])}")
        for teste in self.resultados['testes_realizados']:
            print(f"   ‚úÖ {teste}")
        
        # Status dos modelos
        if self.resultados['modelos_testados']:
            modelos_ok = sum(1 for m in self.resultados['modelos_testados'].values() 
                           if m.get('status') == 'carregado_com_sucesso')
            total = len(self.resultados['modelos_testados'])
            print(f"\nü§ñ Modelos: {modelos_ok}/{total} funcionando")
        
        # Performance
        if 'performance_geral' in self.resultados:
            perf = self.resultados['performance_geral']
            print(f"\n‚ö° Performance:")
            print(f"   ‚è±Ô∏è  Carregamento: {perf.get('tempo_carregamento_modelos', 0):.2f}s")
            print(f"   üíæ Mem√≥ria: {perf.get('uso_memoria', 0):.2f}MB")
        
        # Recomenda√ß√µes principais
        if self.resultados['recomendacoes']:
            print(f"\nüí° Principais recomenda√ß√µes:")
            for i, rec in enumerate(self.resultados['recomendacoes'][:3], 1):
                print(f"   {i}. {rec}")
        
        print("\n" + "=" * 60)
        print("‚úÖ TESTE COMPLETO FINALIZADO COM SUCESSO!")
        print("=" * 60)

def main():
    """Fun√ß√£o principal"""
    teste = TesteSistemaOtimizado()
    teste.executar_teste_completo()

if __name__ == "__main__":
    main()