import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    classification_report, 
    confusion_matrix, 
    roc_auc_score
)
from sklearn.model_selection import train_test_split

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dados.dados import carregar_dados, preparar_dados
from experimentos.feature_engineering import FeatureEngineeringLotofacil

def formatar_porcentagem(valor):
    """Converte decimal para porcentagem formatada (ex: 0.85 -> 85.0%)"""
    return f"{valor * 100:.1f}%"

def testar_modelo_existente():
    print("=== TESTE DE MODELO EXISTENTE ===")
    print(f"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Carregar dados validados
    print("\n1. Carregando dados validados...")
    try:
        df = carregar_dados()
        print(f"   ‚úì Dados carregados: {len(df)} concursos")
        
        # Preparar dados b√°sicos
        # Usar o DataFrame original que j√° tem a coluna 'Ganhou'
        df_preparado = df.copy()
        print(f"   ‚úì Dados preparados: {len(df_preparado)} registros")
        print(f"   ‚úì Per√≠odo: {df_preparado['Data Sorteio'].min()} a {df_preparado['Data Sorteio'].max()}")
        print(f"   ‚úì Concursos com ganhadores: {df_preparado['Ganhou'].sum()}/{len(df_preparado)} ({formatar_porcentagem(df_preparado['Ganhou'].mean())})")
        
    except Exception as e:
        print(f"   ‚úó Erro ao carregar dados: {e}")
        return
    
    # 2. Carregar modelo ensemble
    print("\n2. Carregando modelo ensemble...")
    modelo_path = "modelo/optimized_models/ensemble_otimizado.pkl"
    
    try:
        with open(modelo_path, 'rb') as f:
            modelo = pickle.load(f)
        print(f"   ‚úì Modelo carregado: {type(modelo).__name__}")
        print(f"   ‚úì Estimadores: {[name for name, _ in modelo.estimators]}")
        
    except Exception as e:
        print(f"   ‚úó Erro ao carregar modelo: {e}")
        return
    
    # 3. Preparar features (come√ßando apenas com estat√≠sticas)
    print("\n3. Preparando features...")
    try:
        # Inicializar feature engineer
        fe = FeatureEngineeringLotofacil()
        
        # Come√ßar apenas com features estat√≠sticas
        print("   ‚ÑπÔ∏è Criando features estat√≠sticas...")
        features_df = fe.criar_features_estatisticas(df_preparado)
        print(f"   ‚úì Features estat√≠sticas: {features_df.shape[1]} colunas")
        
        # Tentar adicionar features temporais de forma mais robusta
        print("   ‚ÑπÔ∏è Tentando adicionar features temporais...")
        try:
            # Criar um subset menor para teste das features temporais
            df_subset = df_preparado.head(100)  # Usar apenas 100 concursos para teste
            features_temp = fe.criar_features_temporais(df_subset)
            
            if not features_temp.empty and len(features_temp.columns) > 1:
                print(f"   ‚úì Features temporais: {features_temp.shape[1]} colunas")
                
                # Alinhar com features estat√≠sticas
                if 'concurso' in features_temp.columns and 'concurso' in features_df.columns:
                    features_df = pd.merge(features_df, features_temp, on='concurso', how='left')
                    print(f"   ‚úì Features combinadas: {features_df.shape[1]} colunas")
                else:
                    print("   ‚ö†Ô∏è N√£o foi poss√≠vel alinhar features temporais (sem coluna concurso)")
            else:
                print("   ‚ö†Ô∏è Features temporais vazias ou inv√°lidas")
        except Exception as temp_error:
            print(f"   ‚ö†Ô∏è Erro nas features temporais: {temp_error}")
            print("   ‚ÑπÔ∏è Continuando apenas com features estat√≠sticas")
        
        # Preparar targets alinhados com as features
        if 'concurso' in features_df.columns:
            print(f"   ‚ÑπÔ∏è Alinhando targets usando coluna 'concurso'")
            # Alinhar targets com os concursos das features
            concursos_features = features_df['concurso'].values
            targets_alinhados = []
            concursos_nao_encontrados = 0
            
            for concurso in concursos_features:
                idx = df_preparado[df_preparado['Concurso'] == concurso].index
                if len(idx) > 0:
                    ganhou_valor = df_preparado.loc[idx[0], 'Ganhou']
                    # Garantir que seja bin√°rio (0 ou 1)
                    targets_alinhados.append(1 if ganhou_valor > 0 else 0)
                else:
                    targets_alinhados.append(0)  # Default para concursos n√£o encontrados
                    concursos_nao_encontrados += 1
            
            y = np.array(targets_alinhados)
            print(f"   ‚ÑπÔ∏è Concursos n√£o encontrados: {concursos_nao_encontrados}")
            print(f"   ‚ÑπÔ∏è Valores √∫nicos nos targets alinhados: {np.unique(y)}")
            
            # Remover coluna concurso das features
            features_df = features_df.drop('concurso', axis=1)
        else:
            print(f"   ‚ÑπÔ∏è Usando targets diretos (sem coluna concurso)")
            # Usar targets diretos se n√£o h√° coluna concurso
            y_raw = df_preparado['Ganhou'].values[:len(features_df)]
            # Garantir que seja bin√°rio (0 ou 1)
            y = np.array([1 if val > 0 else 0 for val in y_raw])
            print(f"   ‚ÑπÔ∏è Valores √∫nicos nos targets diretos: {np.unique(y)}")
        
        # Converter features para array numpy
        X = features_df.values
        
        print(f"   ‚úì Features extra√≠das: {X.shape}")
        print(f"   ‚úì Targets: {len(y)} ({np.sum(y)} ganhadores)")
        print(f"   ‚úì Features dispon√≠veis: {list(features_df.columns)[:10]}...")  # Mostrar primeiras 10
        
        # Ajustar para 81 features esperadas pelo modelo
        if X.shape[1] < 81:
            print(f"   ‚ö†Ô∏è Preenchendo {81 - X.shape[1]} features faltantes com zeros")
            zeros_padding = np.zeros((X.shape[0], 81 - X.shape[1]))
            X = np.hstack([X, zeros_padding])
            print(f"   ‚úì Features ajustadas para: {X.shape}")
        elif X.shape[1] > 81:
            print(f"   ‚ö†Ô∏è Reduzindo de {X.shape[1]} para 81 features (primeiras 81)")
            X = X[:, :81]
            print(f"   ‚úì Features ajustadas para: {X.shape}")
        
    except Exception as e:
        print(f"   ‚úó Erro ao preparar features: {e}")
        print(f"   Detalhes do erro: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return
    
    # 4. Dividir dados temporalmente (80% treino, 20% teste)
    print("\n4. Dividindo dados temporalmente...")
    try:
        # Divis√£o temporal: primeiros 80% para treino, √∫ltimos 20% para teste
        split_idx = int(len(X) * 0.8)
        
        X_train = X[:split_idx]
        X_test = X[split_idx:]
        y_train = y[:split_idx]
        y_test = y[split_idx:]
        
        print(f"   ‚úì Treino: {len(X_train)} amostras")
        print(f"   ‚úì Teste: {len(X_test)} amostras")
        print(f"   ‚úì Ganhadores no teste: {np.sum(y_test)}")
        
    except Exception as e:
        print(f"   ‚úó Erro na divis√£o temporal: {e}")
        return
    
    # 5. Testar modelo
    print("\n5. Testando modelo...")
    try:
        # Fazer predi√ß√µes
        y_pred = modelo.predict(X_test)
        
        print(f"   ‚ÑπÔ∏è Classes encontradas nas predi√ß√µes: {np.unique(y_pred)}")
        print(f"   ‚ÑπÔ∏è Classes encontradas nos targets de teste: {np.unique(y_test)}")
        print(f"   ‚ÑπÔ∏è Primeiras 10 predi√ß√µes: {y_pred[:10]}")
        print(f"   ‚ÑπÔ∏è Primeiros 10 targets: {y_test[:10]}")
        
        # Tentar obter probabilidades se dispon√≠vel
        try:
            if hasattr(modelo, 'predict_proba'):
                y_pred_proba = modelo.predict_proba(X_test)
                print(f"   ‚ÑπÔ∏è Shape das probabilidades: {y_pred_proba.shape}")
            elif hasattr(modelo, 'decision_function'):
                y_pred_proba = modelo.decision_function(X_test)
            else:
                # Usar as predi√ß√µes como proxy para probabilidades
                y_pred_proba = y_pred.astype(float)
        except Exception as prob_error:
            print(f"   ‚ö†Ô∏è N√£o foi poss√≠vel obter probabilidades: {prob_error}")
            y_pred_proba = y_pred.astype(float)
        
        # Verificar se √© problema bin√°rio ou multiclass
        unique_classes = np.unique(np.concatenate([y_test, y_pred]))
        print(f"   ‚ÑπÔ∏è Classes encontradas: {unique_classes}")
        
        # Calcular m√©tricas b√°sicas
        accuracy = accuracy_score(y_test, y_pred)
        
        # Determinar se √© bin√°rio ou multiclass
        if len(unique_classes) == 2:
            # Problema bin√°rio
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
        else:
            # Problema multiclass - usar m√©dia weighted
            precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        print(f"   ‚úì Acur√°cia: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   ‚úì Precis√£o: {precision:.4f} ({precision*100:.2f}%)")
        print(f"   ‚úì Recall: {recall:.4f} ({recall*100:.2f}%)")
        print(f"   ‚úì F1-Score: {f1:.4f} ({f1*100:.2f}%)")
        
        # Tentar calcular ROC-AUC se temos probabilidades v√°lidas
        try:
            if len(unique_classes) == 2 and len(np.unique(y_pred_proba)) > 1:
                roc_auc = roc_auc_score(y_test, y_pred_proba)
                print(f"   ‚úì ROC-AUC: {roc_auc:.4f} ({roc_auc*100:.2f}%)")
            else:
                print(f"   ‚ö†Ô∏è ROC-AUC n√£o calcul√°vel (multiclass ou probabilidades constantes)")
        except Exception as auc_error:
            print(f"   ‚ö†Ô∏è Erro ao calcular ROC-AUC: {auc_error}")
        
        # Relat√≥rio detalhado
        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
        
        print("\n   üìä M√âTRICAS DETALHADAS:")
        print(f"   ‚Ä¢ Acur√°cia Geral: {formatar_porcentagem(accuracy)}")
        print(f"   ‚Ä¢ Precis√£o (N√£o Ganhou): {formatar_porcentagem(report['0']['precision'])}")
        print(f"   ‚Ä¢ Recall (N√£o Ganhou): {formatar_porcentagem(report['0']['recall'])}")
        print(f"   ‚Ä¢ F1-Score (N√£o Ganhou): {formatar_porcentagem(report['0']['f1-score'])}")
        
        if '1' in report:
            print(f"   ‚Ä¢ Precis√£o (Ganhou): {formatar_porcentagem(report['1']['precision'])}")
            print(f"   ‚Ä¢ Recall (Ganhou): {formatar_porcentagem(report['1']['recall'])}")
            print(f"   ‚Ä¢ F1-Score (Ganhou): {formatar_porcentagem(report['1']['f1-score'])}")
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred)
        print(f"\n   üìà MATRIZ DE CONFUS√ÉO:")
        print(f"   ‚úì Verdadeiros Negativos: {cm[0,0]}")
        print(f"   ‚úì Falsos Positivos: {cm[0,1]}")
        print(f"   ‚úì Falsos Negativos: {cm[1,0]}")
        print(f"   ‚úì Verdadeiros Positivos: {cm[1,1]}")
        
        # An√°lise por classe
        print("\n   üéØ AN√ÅLISE POR CLASSE:")
        print(f"   ‚úì Classe 0 (Sem ganhador): Precis√£o={report['0']['precision']*100:.2f}%, Recall={report['0']['recall']*100:.2f}%")
        print(f"   ‚úì Classe 1 (Com ganhador): Precis√£o={report['1']['precision']*100:.2f}%, Recall={report['1']['recall']*100:.2f}%")
        
    except Exception as e:
        print(f"   ‚úó Erro no teste do modelo: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 6. An√°lise de probabilidades
    print("\n6. Analisando probabilidades...")
    prob_ganhou = None
    try:
        # Estat√≠sticas das probabilidades
        if hasattr(y_pred_proba, 'shape') and len(y_pred_proba.shape) > 1 and y_pred_proba.shape[1] > 1:
            prob_ganhou = y_pred_proba[:, 1]
        elif hasattr(y_pred_proba, 'shape') and len(y_pred_proba.shape) > 1:
            prob_ganhou = y_pred_proba[:, 0]
        else:
            prob_ganhou = y_pred_proba
        
        print(f"   ‚Ä¢ Probabilidade m√©dia de ganhar: {formatar_porcentagem(np.mean(prob_ganhou))}")
        print(f"   ‚Ä¢ Probabilidade m√°xima: {formatar_porcentagem(np.max(prob_ganhou))}")
        print(f"   ‚Ä¢ Probabilidade m√≠nima: {formatar_porcentagem(np.min(prob_ganhou))}")
        print(f"   ‚Ä¢ Desvio padr√£o: {formatar_porcentagem(np.std(prob_ganhou))}")
        
    except Exception as e:
        print(f"   ‚úó Erro na an√°lise de probabilidades: {e}")
        # Usar valores padr√£o se n√£o conseguir calcular probabilidades
        prob_ganhou = y_pred.astype(float)
    
    # 7. Salvar relat√≥rio
    print("\n7. Salvando relat√≥rio...")
    relatorio = None
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Garantir que prob_ganhou existe
        if prob_ganhou is None:
            prob_ganhou = y_pred.astype(float)
        
        relatorio = {
            'timestamp': timestamp,
            'teste_realizado': 'Modelo Ensemble Existente',
            'dados': {
                'total_concursos': len(df),
                'total_features': X.shape[1],
                'treino_amostras': len(X_train),
                'teste_amostras': len(X_test),
                'ganhadores_teste': int(np.sum(y_test))
            },
            'modelo': {
                'tipo': type(modelo).__name__,
                'estimadores': [name for name, _ in modelo.estimators] if hasattr(modelo, 'estimators') else ['Modelo √önico'],
                'path': modelo_path
            },
            'metricas': {
                'acuracia_geral': float(accuracy),
                'acuracia_formatada': formatar_porcentagem(accuracy),
                'relatorio_classificacao': report,
                'matriz_confusao': cm.tolist(),
                'probabilidades': {
                    'media': float(np.mean(prob_ganhou)),
                    'maxima': float(np.max(prob_ganhou)),
                    'minima': float(np.min(prob_ganhou)),
                    'desvio_padrao': float(np.std(prob_ganhou))
                }
            },
            'analise': {
                'status': 'TESTADO',
                'observacoes': [
                    f"Modelo testado com {len(X_test)} amostras de teste",
                    f"Acur√°cia atual: {formatar_porcentagem(accuracy)}",
                    "Meta desejada: 85-90% de acur√°cia",
                    "Necess√°rio retreinamento para melhorar performance" if accuracy < 0.85 else "Performance dentro da meta"
                ]
            }
        }
        
        # Salvar relat√≥rio
        os.makedirs('experimentos/resultados', exist_ok=True)
        relatorio_path = f'experimentos/resultados/teste_modelo_existente_{timestamp}.json'
        
        with open(relatorio_path, 'w', encoding='utf-8') as f:
            json.dump(relatorio, f, indent=2, ensure_ascii=False)
        
        print(f"   ‚úì Relat√≥rio salvo: {relatorio_path}")
        
    except Exception as e:
        print(f"   ‚úó Erro ao salvar relat√≥rio: {e}")
        # Criar relat√≥rio b√°sico em caso de erro
        relatorio = {
            'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'teste_realizado': 'Modelo Ensemble Existente',
            'status': 'ERRO_NO_SALVAMENTO',
            'acuracia': float(accuracy) if 'accuracy' in locals() else 0.0
        }
    
    # 8. Conclus√£o
    print("\n" + "="*50)
    print("üìã RESUMO DO TESTE:")
    print(f"‚Ä¢ Modelo: Ensemble Otimizado")
    print(f"‚Ä¢ Dados: {len(df)} concursos validados")
    print(f"‚Ä¢ Acur√°cia Atual: {formatar_porcentagem(accuracy)}")
    print(f"‚Ä¢ Meta Desejada: 85.0% - 90.0%")
    
    if accuracy >= 0.85:
        print(f"‚Ä¢ Status: ‚úÖ DENTRO DA META")
    else:
        print(f"‚Ä¢ Status: ‚ö†Ô∏è  ABAIXO DA META - NECESS√ÅRIO RETREINAMENTO")
    
    print("="*50)
    
    return relatorio

if __name__ == "__main__":
    testar_modelo_existente()