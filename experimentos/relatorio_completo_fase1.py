#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Relat√≥rio Completo - Fase 1: An√°lise Explorat√≥ria e Prepara√ß√£o do Ambiente

Este m√≥dulo gera um relat√≥rio detalhado consolidando todas as an√°lises
realizadas na Fase 1 do projeto de otimiza√ß√£o da IA Lotof√°cil.
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass

@dataclass
class AnalysisInsight:
    """Estrutura para insights da an√°lise"""
    category: str
    title: str
    description: str
    impact: str  # 'high', 'medium', 'low'
    recommendation: str
    priority: int  # 1-5, sendo 1 mais priorit√°rio

class ComprehensiveReportGenerator:
    """
    Gerador de relat√≥rio completo da Fase 1
    """
    
    def __init__(self, results_dir: str = "experimentos/resultados"):
        """
        Inicializa o gerador de relat√≥rio
        
        Args:
            results_dir: Diret√≥rio com os resultados das an√°lises
        """
        self.results_dir = Path(results_dir)
        self.insights = []
        self.recommendations = []
        
    def load_analysis_results(self) -> Dict[str, Any]:
        """
        Carrega todos os resultados das an√°lises realizadas
        
        Returns:
            Dicion√°rio com todos os resultados
        """
        results = {
            'exploratory_analysis': None,
            'model_limitations': None,
            'metrics_evaluation': None
        }
        
        # Carregar an√°lise explorat√≥ria
        exploratory_files = list(self.results_dir.glob("*exploratory_analysis*.json"))
        if exploratory_files:
            with open(exploratory_files[-1], 'r', encoding='utf-8') as f:
                results['exploratory_analysis'] = json.load(f)
        
        # Carregar an√°lise de limita√ß√µes
        limitations_files = list(self.results_dir.glob("*model_limitations*.json"))
        if limitations_files:
            with open(limitations_files[-1], 'r', encoding='utf-8') as f:
                results['model_limitations'] = json.load(f)
        
        # Carregar m√©tricas
        metrics_files = list(self.results_dir.glob("*metricas_*.json"))
        if metrics_files:
            with open(metrics_files[-1], 'r', encoding='utf-8') as f:
                results['metrics_evaluation'] = json.load(f)
        
        return results
    
    def analyze_exploratory_insights(self, exploratory_data: Dict[str, Any]) -> List[AnalysisInsight]:
        """
        Extrai insights da an√°lise explorat√≥ria
        
        Args:
            exploratory_data: Dados da an√°lise explorat√≥ria
            
        Returns:
            Lista de insights
        """
        insights = []
        
        if not exploratory_data:
            return insights
        
        # An√°lise de frequ√™ncias
        if 'frequency_analysis' in exploratory_data:
            freq_data = exploratory_data['frequency_analysis']
            
            # N√∫meros mais frequentes
            most_frequent = freq_data.get('most_frequent_numbers', [])
            if most_frequent:
                insights.append(AnalysisInsight(
                    category="Padr√µes de Frequ√™ncia",
                    title="N√∫meros Mais Frequentes Identificados",
                    description=f"Os n√∫meros {most_frequent[:5]} aparecem com maior frequ√™ncia nos sorteios.",
                    impact="medium",
                    recommendation="Considerar peso maior para n√∫meros frequentes no modelo, mas balancear com an√°lise temporal.",
                    priority=3
                ))
            
            # Desvio padr√£o das frequ√™ncias
            freq_std = freq_data.get('frequency_std', 0)
            if freq_std > 0.05:
                insights.append(AnalysisInsight(
                    category="Distribui√ß√£o",
                    title="Alta Variabilidade nas Frequ√™ncias",
                    description=f"Desvio padr√£o das frequ√™ncias: {freq_std:.4f}. Indica distribui√ß√£o n√£o uniforme.",
                    impact="high",
                    recommendation="Implementar normaliza√ß√£o adaptativa e features de frequ√™ncia relativa.",
                    priority=2
                ))
        
        # An√°lise temporal
        if 'temporal_analysis' in exploratory_data:
            temporal_data = exploratory_data['temporal_analysis']
            
            # Tend√™ncias temporais
            if 'trend_strength' in temporal_data:
                trend_strength = temporal_data['trend_strength']
                if trend_strength > 0.3:
                    insights.append(AnalysisInsight(
                        category="Padr√µes Temporais",
                        title="Tend√™ncias Temporais Significativas",
                        description=f"For√ßa da tend√™ncia temporal: {trend_strength:.3f}. Padr√µes sazonais detectados.",
                        impact="high",
                        recommendation="Incorporar features temporais (dia da semana, m√™s, sazonalidade) no modelo.",
                        priority=1
                    ))
        
        # An√°lise de correla√ß√µes
        if 'correlation_analysis' in exploratory_data:
            corr_data = exploratory_data['correlation_analysis']
            
            # Correla√ß√µes fortes
            strong_correlations = corr_data.get('strong_correlations', [])
            if len(strong_correlations) > 5:
                insights.append(AnalysisInsight(
                    category="Correla√ß√µes",
                    title="M√∫ltiplas Correla√ß√µes Fortes Detectadas",
                    description=f"{len(strong_correlations)} pares de n√∫meros com correla√ß√£o > 0.3.",
                    impact="medium",
                    recommendation="Implementar regulariza√ß√£o para evitar overfitting e considerar PCA.",
                    priority=3
                ))
        
        return insights
    
    def analyze_limitations_insights(self, limitations_data: Dict[str, Any]) -> List[AnalysisInsight]:
        """
        Extrai insights da an√°lise de limita√ß√µes
        
        Args:
            limitations_data: Dados da an√°lise de limita√ß√µes
            
        Returns:
            Lista de insights
        """
        insights = []
        
        if not limitations_data:
            return insights
        
        # Analisar limita√ß√µes por categoria
        limitations = limitations_data.get('limitations', {})
        
        for category, category_limitations in limitations.items():
            if isinstance(category_limitations, list):
                for limitation in category_limitations:
                    if isinstance(limitation, dict):
                        severity = limitation.get('severity', 'medium')
                        description = limitation.get('description', '')
                        
                        # Mapear severidade para prioridade
                        priority_map = {'high': 1, 'medium': 2, 'low': 3}
                        priority = priority_map.get(severity, 2)
                        
                        insights.append(AnalysisInsight(
                            category=f"Limita√ß√£o - {category.title()}",
                            title=limitation.get('issue', 'Limita√ß√£o Identificada'),
                            description=description,
                            impact=severity,
                            recommendation=limitation.get('recommendation', 'Revisar implementa√ß√£o'),
                            priority=priority
                        ))
        
        return insights
    
    def analyze_metrics_insights(self, metrics_data: Dict[str, Any]) -> List[AnalysisInsight]:
        """
        Extrai insights da avalia√ß√£o de m√©tricas
        
        Args:
            metrics_data: Dados da avalia√ß√£o de m√©tricas
            
        Returns:
            Lista de insights
        """
        insights = []
        
        if not metrics_data:
            return insights
        
        # Score geral
        overall_score = metrics_data.get('overall_score', 0)
        if overall_score < 0.5:
            insights.append(AnalysisInsight(
                category="Performance Geral",
                title="Score Geral Abaixo do Esperado",
                description=f"Score geral: {overall_score:.3f}. Performance atual insuficiente.",
                impact="high",
                recommendation="Implementar otimiza√ß√µes de arquitetura e feature engineering avan√ßado.",
                priority=1
            ))
        
        # Hit rates
        hit_rates = metrics_data.get('hit_rates', {})
        hit_rate_15 = hit_rates.get('hit_rate_15', 0)
        if hit_rate_15 < 0.1:
            insights.append(AnalysisInsight(
                category="Taxa de Acerto",
                title="Taxa de Acerto para 15 N√∫meros Baixa",
                description=f"Hit rate para 15 n√∫meros: {hit_rate_15:.3f}. Muito abaixo do ideal.",
                impact="high",
                recommendation="Revisar estrat√©gia de sele√ß√£o de n√∫meros e implementar ensemble methods.",
                priority=1
            ))
        
        # ROI
        roi_data = metrics_data.get('roi_analysis', {})
        roi_percentage = roi_data.get('roi_percentage', -100)
        if roi_percentage < 0:
            insights.append(AnalysisInsight(
                category="Viabilidade Econ√¥mica",
                title="ROI Negativo",
                description=f"ROI: {roi_percentage:.1f}%. Modelo n√£o √© economicamente vi√°vel.",
                impact="high",
                recommendation="Focar em melhorar precis√£o antes de considerar aplica√ß√£o pr√°tica.",
                priority=2
            ))
        
        # Calibra√ß√£o
        calibration = metrics_data.get('calibration', {})
        brier_score = calibration.get('brier_score', 1)
        if brier_score > 0.25:
            insights.append(AnalysisInsight(
                category="Calibra√ß√£o",
                title="Probabilidades Mal Calibradas",
                description=f"Brier Score: {brier_score:.3f}. Probabilidades n√£o refletem confian√ßa real.",
                impact="medium",
                recommendation="Implementar calibra√ß√£o de probabilidades (Platt scaling ou isotonic regression).",
                priority=2
            ))
        
        return insights
    
    def generate_recommendations(self, all_insights: List[AnalysisInsight]) -> List[Dict[str, Any]]:
        """
        Gera recomenda√ß√µes consolidadas baseadas nos insights
        
        Args:
            all_insights: Lista de todos os insights
            
        Returns:
            Lista de recomenda√ß√µes priorizadas
        """
        recommendations = []
        
        # Agrupar insights por prioridade
        high_priority = [i for i in all_insights if i.priority == 1]
        medium_priority = [i for i in all_insights if i.priority == 2]
        low_priority = [i for i in all_insights if i.priority >= 3]
        
        # Recomenda√ß√µes de alta prioridade
        if high_priority:
            recommendations.append({
                'phase': 'Fase 2 - Otimiza√ß√µes Cr√≠ticas',
                'priority': 'Alta',
                'timeline': '1-2 semanas',
                'actions': [
                    'Implementar feature engineering avan√ßado com features temporais',
                    'Otimizar arquitetura do modelo (ensemble methods)',
                    'Melhorar estrat√©gia de sele√ß√£o de n√∫meros',
                    'Implementar valida√ß√£o temporal robusta'
                ],
                'expected_impact': 'Melhoria significativa na performance (20-30%)',
                'resources_needed': 'Desenvolvedor s√™nior, 40-60 horas'
            })
        
        # Recomenda√ß√µes de m√©dia prioridade
        if medium_priority:
            recommendations.append({
                'phase': 'Fase 3 - Refinamentos',
                'priority': 'M√©dia',
                'timeline': '2-3 semanas',
                'actions': [
                    'Implementar calibra√ß√£o de probabilidades',
                    'Otimizar hiperpar√¢metros com Bayesian Optimization',
                    'Adicionar regulariza√ß√£o adaptativa',
                    'Implementar an√°lise de feature importance'
                ],
                'expected_impact': 'Melhoria moderada na confiabilidade (10-15%)',
                'resources_needed': 'Desenvolvedor pleno, 30-40 horas'
            })
        
        # Recomenda√ß√µes de baixa prioridade
        if low_priority:
            recommendations.append({
                'phase': 'Fase 4 - Melhorias Incrementais',
                'priority': 'Baixa',
                'timeline': '3-4 semanas',
                'actions': [
                    'Implementar monitoramento cont√≠nuo',
                    'Otimizar performance computacional',
                    'Adicionar explicabilidade do modelo',
                    'Implementar A/B testing framework'
                ],
                'expected_impact': 'Melhorias operacionais e de manutenibilidade',
                'resources_needed': 'Desenvolvedor j√∫nior, 20-30 horas'
            })
        
        return recommendations
    
    def create_executive_summary(self, results: Dict[str, Any], insights: List[AnalysisInsight]) -> str:
        """
        Cria resumo executivo
        
        Args:
            results: Resultados das an√°lises
            insights: Lista de insights
            
        Returns:
            Resumo executivo em texto
        """
        summary = []
        
        summary.append("# RESUMO EXECUTIVO - FASE 1")
        summary.append("\n## Situa√ß√£o Atual")
        
        # Status geral
        metrics_data = results.get('metrics_evaluation', {})
        overall_score = metrics_data.get('overall_score', 0)
        
        if overall_score < 0.3:
            status = "CR√çTICO"
        elif overall_score < 0.5:
            status = "NECESSITA MELHORIAS"
        elif overall_score < 0.7:
            status = "SATISFAT√ìRIO"
        else:
            status = "BOM"
        
        summary.append(f"**Status do Modelo:** {status} (Score: {overall_score:.3f})")
        
        # Principais descobertas
        summary.append("\n## Principais Descobertas")
        
        high_impact_insights = [i for i in insights if i.impact == 'high']
        for i, insight in enumerate(high_impact_insights[:3], 1):
            summary.append(f"{i}. **{insight.title}:** {insight.description}")
        
        # Pr√≥ximos passos
        summary.append("\n## Pr√≥ximos Passos Cr√≠ticos")
        summary.append("1. Implementar feature engineering temporal")
        summary.append("2. Otimizar arquitetura com ensemble methods")
        summary.append("3. Melhorar calibra√ß√£o de probabilidades")
        
        # Estimativa de melhoria
        summary.append("\n## Potencial de Melhoria")
        summary.append(f"**Estimativa:** 25-40% de melhoria na performance com as otimiza√ß√µes propostas")
        summary.append(f"**Timeline:** 4-6 semanas para implementa√ß√£o completa")
        summary.append(f"**ROI Esperado:** Modelo vi√°vel economicamente ap√≥s otimiza√ß√µes")
        
        return "\n".join(summary)
    
    def generate_technical_details(self, results: Dict[str, Any]) -> str:
        """
        Gera se√ß√£o de detalhes t√©cnicos
        
        Args:
            results: Resultados das an√°lises
            
        Returns:
            Detalhes t√©cnicos formatados
        """
        details = []
        
        details.append("# DETALHES T√âCNICOS")
        
        # An√°lise Explorat√≥ria
        if results.get('exploratory_analysis'):
            details.append("\n## An√°lise Explorat√≥ria")
            exp_data = results['exploratory_analysis']
            
            details.append(f"**Dataset:** {exp_data.get('data_info', {}).get('total_samples', 'N/A')} amostras")
            details.append(f"**Per√≠odo:** {exp_data.get('data_info', {}).get('date_range', 'N/A')}")
            
            # Estat√≠sticas principais
            if 'summary_statistics' in exp_data:
                stats = exp_data['summary_statistics']
                details.append(f"**M√©dia de n√∫meros pares:** {stats.get('avg_even_numbers', 0):.2f}")
                details.append(f"**M√©dia de n√∫meros baixos:** {stats.get('avg_low_numbers', 0):.2f}")
                details.append(f"**Soma m√©dia:** {stats.get('avg_sum', 0):.1f}")
        
        # Limita√ß√µes do Modelo
        if results.get('model_limitations'):
            details.append("\n## Limita√ß√µes Identificadas")
            limitations = results['model_limitations'].get('limitations', {})
            
            for category, issues in limitations.items():
                if isinstance(issues, list) and issues:
                    details.append(f"\n### {category.title()}")
                    for issue in issues[:3]:  # Top 3 issues
                        if isinstance(issue, dict):
                            details.append(f"- **{issue.get('issue', 'N/A')}:** {issue.get('description', 'N/A')}")
        
        # M√©tricas de Performance
        if results.get('metrics_evaluation'):
            details.append("\n## M√©tricas de Performance")
            metrics = results['metrics_evaluation']
            
            # M√©tricas b√°sicas
            basic = metrics.get('basic_metrics', {})
            details.append(f"**Accuracy:** {basic.get('accuracy', 0):.3f}")
            details.append(f"**F1-Score:** {basic.get('f1_score', 0):.3f}")
            
            # Hit rates
            hit_rates = metrics.get('hit_rates', {})
            for k in [11, 12, 13, 14, 15]:
                rate = hit_rates.get(f'hit_rate_{k}', 0)
                details.append(f"**Hit Rate {k} n√∫meros:** {rate:.3f}")
            
            # ROI
            roi = metrics.get('roi_analysis', {})
            details.append(f"**ROI:** {roi.get('roi_percentage', 0):.1f}%")
            details.append(f"**Investimento total:** R$ {roi.get('total_investment', 0):.2f}")
            details.append(f"**Retorno total:** R$ {roi.get('total_return', 0):.2f}")
        
        return "\n".join(details)
    
    def generate_complete_report(self) -> str:
        """
        Gera o relat√≥rio completo da Fase 1
        
        Returns:
            Caminho do arquivo do relat√≥rio
        """
        print("\n=== GERANDO RELAT√ìRIO COMPLETO DA FASE 1 ===")
        
        # Carregar resultados
        print("Carregando resultados das an√°lises...")
        results = self.load_analysis_results()
        
        # Extrair insights
        print("Extraindo insights...")
        all_insights = []
        
        if results['exploratory_analysis']:
            all_insights.extend(self.analyze_exploratory_insights(results['exploratory_analysis']))
        
        if results['model_limitations']:
            all_insights.extend(self.analyze_limitations_insights(results['model_limitations']))
        
        if results['metrics_evaluation']:
            all_insights.extend(self.analyze_metrics_insights(results['metrics_evaluation']))
        
        # Gerar recomenda√ß√µes
        print("Gerando recomenda√ß√µes...")
        recommendations = self.generate_recommendations(all_insights)
        
        # Criar relat√≥rio
        print("Compilando relat√≥rio...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = self.results_dir / f"relatorio_completo_fase1_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            # Cabe√ßalho
            f.write("# RELAT√ìRIO COMPLETO - FASE 1\n")
            f.write("## An√°lise Explorat√≥ria e Prepara√ß√£o do Ambiente\n\n")
            f.write(f"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
            f.write(f"**Vers√£o:** 1.0\n")
            f.write(f"**Autor:** Sistema de An√°lise Automatizada\n\n")
            
            # Resumo executivo
            executive_summary = self.create_executive_summary(results, all_insights)
            f.write(executive_summary)
            f.write("\n\n---\n\n")
            
            # Detalhes t√©cnicos
            technical_details = self.generate_technical_details(results)
            f.write(technical_details)
            f.write("\n\n---\n\n")
            
            # Insights detalhados
            f.write("# INSIGHTS DETALHADOS\n\n")
            
            # Agrupar por categoria
            categories = {}
            for insight in all_insights:
                if insight.category not in categories:
                    categories[insight.category] = []
                categories[insight.category].append(insight)
            
            for category, category_insights in categories.items():
                f.write(f"## {category}\n\n")
                
                for insight in sorted(category_insights, key=lambda x: x.priority):
                    f.write(f"### {insight.title}\n")
                    f.write(f"**Impacto:** {insight.impact.upper()}\n")
                    f.write(f"**Prioridade:** {insight.priority}\n")
                    f.write(f"**Descri√ß√£o:** {insight.description}\n")
                    f.write(f"**Recomenda√ß√£o:** {insight.recommendation}\n\n")
            
            # Recomenda√ß√µes
            f.write("\n---\n\n")
            f.write("# ROADMAP DE OTIMIZA√á√ÉO\n\n")
            
            for i, rec in enumerate(recommendations, 1):
                f.write(f"## {rec['phase']}\n")
                f.write(f"**Prioridade:** {rec['priority']}\n")
                f.write(f"**Timeline:** {rec['timeline']}\n")
                f.write(f"**Impacto Esperado:** {rec['expected_impact']}\n")
                f.write(f"**Recursos Necess√°rios:** {rec['resources_needed']}\n\n")
                
                f.write("**A√ß√µes:**\n")
                for action in rec['actions']:
                    f.write(f"- {action}\n")
                f.write("\n")
            
            # Conclus√µes
            f.write("\n---\n\n")
            f.write("# CONCLUS√ïES\n\n")
            f.write("A Fase 1 do projeto de otimiza√ß√£o da IA Lotof√°cil foi conclu√≠da com sucesso. ")
            f.write("As an√°lises realizadas identificaram pontos cr√≠ticos de melhoria e estabeleceram ")
            f.write("uma base s√≥lida para as pr√≥ximas fases de otimiza√ß√£o.\n\n")
            
            f.write("**Principais Conquistas:**\n")
            f.write("- Estrutura completa de experimentos implementada\n")
            f.write("- Sistema de logging e m√©tricas avan√ßadas funcionais\n")
            f.write("- Limita√ß√µes do modelo atual mapeadas e priorizadas\n")
            f.write("- Roadmap detalhado para otimiza√ß√µes futuras\n\n")
            
            f.write("**Pr√≥ximos Passos:**\n")
            f.write("1. Iniciar Fase 2 com foco em feature engineering temporal\n")
            f.write("2. Implementar ensemble methods para melhorar performance\n")
            f.write("3. Estabelecer pipeline de valida√ß√£o cont√≠nua\n")
            f.write("4. Monitorar m√©tricas de performance em tempo real\n\n")
            
            # Anexos
            f.write("\n---\n\n")
            f.write("# ANEXOS\n\n")
            f.write("## Arquivos Gerados\n")
            f.write("- `experiment_logger.py`: Sistema de logging\n")
            f.write("- `exploratory_analysis.py`: An√°lise explorat√≥ria\n")
            f.write("- `model_limitations_analyzer.py`: An√°lise de limita√ß√µes\n")
            f.write("- `advanced_metrics.py`: Sistema de m√©tricas\n")
            f.write("- Dashboards e visualiza√ß√µes em `experimentos/resultados/`\n\n")
            
            f.write("## Estrutura de Diret√≥rios\n")
            f.write("```\n")
            f.write("experimentos/\n")
            f.write("‚îú‚îÄ‚îÄ modelos/          # Modelos experimentais\n")
            f.write("‚îú‚îÄ‚îÄ resultados/       # Resultados e relat√≥rios\n")
            f.write("‚îú‚îÄ‚îÄ logs/            # Logs de experimentos\n")
            f.write("‚îú‚îÄ‚îÄ dados_processados/ # Dados processados\n")
            f.write("‚îú‚îÄ‚îÄ experiment_logger.py\n")
            f.write("‚îú‚îÄ‚îÄ exploratory_analysis.py\n")
            f.write("‚îú‚îÄ‚îÄ model_limitations_analyzer.py\n")
            f.write("‚îî‚îÄ‚îÄ advanced_metrics.py\n")
            f.write("```\n")
        
        print(f"\nRelat√≥rio completo gerado: {report_path}")
        print(f"Total de insights identificados: {len(all_insights)}")
        print(f"Recomenda√ß√µes geradas: {len(recommendations)} fases")
        
        return str(report_path)
    
    def create_summary_dashboard(self, results: Dict[str, Any]) -> str:
        """
        Cria dashboard resumo da Fase 1
        
        Args:
            results: Resultados das an√°lises
            
        Returns:
            Caminho do dashboard
        """
        print("Gerando dashboard resumo...")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Dashboard Resumo - Fase 1: An√°lise e Prepara√ß√£o', fontsize=16, fontweight='bold')
        
        # 1. Status Geral
        metrics_data = results.get('metrics_evaluation', {})
        overall_score = metrics_data.get('overall_score', 0)
        
        # Gauge chart para score geral
        theta = np.linspace(0, np.pi, 100)
        r = np.ones_like(theta)
        
        ax1 = plt.subplot(2, 2, 1, projection='polar')
        ax1.plot(theta, r, 'lightgray', linewidth=20)
        
        # Score atual
        score_theta = overall_score * np.pi
        score_range = np.linspace(0, score_theta, int(overall_score * 100))
        ax1.plot(score_range, np.ones_like(score_range), 'green' if overall_score > 0.5 else 'red', linewidth=20)
        
        ax1.set_ylim(0, 1.2)
        ax1.set_title(f'Score Geral: {overall_score:.3f}', pad=20)
        ax1.set_theta_zero_location('W')
        ax1.set_theta_direction(1)
        ax1.set_thetagrids([])
        ax1.set_rgrids([])
        
        # 2. Hit Rates
        hit_rates = metrics_data.get('hit_rates', {})
        k_values = [11, 12, 13, 14, 15]
        hit_values = [hit_rates.get(f'hit_rate_{k}', 0) for k in k_values]
        
        axes[0, 1].bar(k_values, hit_values, color=['lightblue', 'skyblue', 'deepskyblue', 'dodgerblue', 'blue'])
        axes[0, 1].set_title('Taxa de Acerto por Quantidade de N√∫meros')
        axes[0, 1].set_xlabel('N√∫meros Selecionados')
        axes[0, 1].set_ylabel('Taxa de Acerto')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ROI Analysis
        roi_data = metrics_data.get('roi_analysis', {})
        roi_percentage = roi_data.get('roi_percentage', 0)
        
        colors = ['red' if roi_percentage < 0 else 'green']
        axes[1, 0].bar(['ROI'], [abs(roi_percentage)], color=colors)
        axes[1, 0].set_title(f'ROI: {roi_percentage:.1f}%')
        axes[1, 0].set_ylabel('ROI (%)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Limita√ß√µes por Categoria
        limitations_data = results.get('model_limitations', {})
        if limitations_data and 'limitations' in limitations_data:
            limitations = limitations_data['limitations']
            categories = list(limitations.keys())
            counts = [len(limitations[cat]) if isinstance(limitations[cat], list) else 1 for cat in categories]
            
            if categories and counts:
                axes[1, 1].pie(counts, labels=categories, autopct='%1.0f%%', startangle=90)
                axes[1, 1].set_title('Distribui√ß√£o de Limita√ß√µes')
        else:
            axes[1, 1].text(0.5, 0.5, 'Dados de limita√ß√µes\nn√£o dispon√≠veis', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('Limita√ß√µes do Modelo')
        
        plt.tight_layout()
        
        # Salvar dashboard
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        dashboard_path = self.results_dir / f"dashboard_resumo_fase1_{timestamp}.png"
        
        plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Dashboard resumo salvo: {dashboard_path}")
        return str(dashboard_path)


# Execu√ß√£o principal
if __name__ == "__main__":
    print("=== GERADOR DE RELAT√ìRIO COMPLETO - FASE 1 ===")
    
    # Criar gerador de relat√≥rio
    report_generator = ComprehensiveReportGenerator()
    
    # Gerar relat√≥rio completo
    report_path = report_generator.generate_complete_report()
    
    # Carregar resultados para dashboard
    results = report_generator.load_analysis_results()
    
    # Gerar dashboard resumo
    dashboard_path = report_generator.create_summary_dashboard(results)
    
    print("\n=== FASE 1 CONCLU√çDA COM SUCESSO ===")
    print(f"üìä Relat√≥rio completo: {report_path}")
    print(f"üìà Dashboard resumo: {dashboard_path}")
    print("\nüéØ Pr√≥ximos passos: Iniciar Fase 2 - Otimiza√ß√µes de Feature Engineering")
    print("\n‚úÖ Estrutura de experimentos pronta para desenvolvimento avan√ßado!")